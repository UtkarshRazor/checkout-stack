{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCCDrL9Y1iEAAr4koJ7BVv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanDudeja/checkout-stack/blob/main/Automating_checkout_stack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¡ How to Execute the Script?\n",
        "Follow these steps to execute the script and extract website URLs from an Excel column:\n",
        "\n",
        "---\n",
        "1. **Understand the Procedure**:</br>\n",
        " Begin by reviewing the provided procedure to grasp the steps involved in the process.</br>\n",
        "\n",
        "---\n",
        "2. **Provide Details**: Enter the required details for the procedure as mentioned in Step 1. ```Replace the placeholders with the actual values```</br>\n",
        " a. Set the ```inputFileName``` variable to the name of the Excel file containing the data.</br>\n",
        "  b. Specify the column index with the website URLs using the ```columnIndex``` variable.</br>\n",
        "  c.Specify the sheet index using ```sheetIndex``` vairable.</br>\n",
        "  d. Choose an appropriate name for the output file and set it as the ```outputFileName``` variable.\n",
        "---\n",
        "3. **Run the Script:**</br>\n",
        "Navigate to \"Runtime\" and select \"Run all\" to initiate the script's execution.\n",
        "\n",
        "---\n",
        "4. **Allow Access Popups:**</br>\n",
        "Once the script starts running, you will encounter two popups requesting access permissions.</br>\n",
        "a. Grant access to Google Colab for accessing Google Sheets.</br>\n",
        "b. Grant access to Google Colab for accessing Google Drive. </br>\n",
        "---\n",
        "5. **Wait for Output:**</br>\n",
        "Allow the script to process the data and extract the website URLs.\n",
        "Wait for the script to complete its execution.\n"
      ],
      "metadata": {
        "id": "ZRh548bYKx65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“– **Procedure**\n",
        "---\n",
        "Step 1: *Set Up Variables*</br>\n",
        "1. Assign the input file name to the variable ```inputFileName```.</br>\n",
        "2. Determine the sheet index and assign it to vairable ```sheetIndex```.</br>\n",
        "3. Determine the column index containing website URLs and assign it to the variable ```columnIndex```.</br>\n",
        "> For example, if the website URL is in column A, set ```columnIndex``` to 0.</br>\n",
        "> For column B, set ```columnIndex``` to 1, and so on.</br>\n",
        "\n",
        "4. Assign the desired output file name to the variable ```outputFileName```.</br>\n",
        "Make sure no file with same output name is present in your google drive.\n",
        "\n",
        "---\n",
        "Step 2: *Acess Management*</br>\n",
        "Allow google colab to access drive and google sheets.\n",
        "\n",
        "---\n",
        "Step 3: *Extract details from Website URL*</br>\n",
        "Loop through the selected column's cells and extract the website details.\n",
        "Store the extracted details in a list or an appropriate data structure.\n",
        "\n",
        "---\n",
        "Step 4: *Write to Output File*</br>\n",
        "Create the output file using the outputFileName.\n",
        "Write the extracted website details to the output file.\n",
        "\n",
        "---\n",
        "Step 5: *Completion*</br>\n",
        "Verify the output file in your google drive.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mk0m8wRMK6wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 1\n",
        "inputFileName = 'Copy of Need Checkout Stack Info'\n",
        "sheetIndex = 0\n",
        "columnIndex = 1\n",
        "outputFileName = 'outputfile'"
      ],
      "metadata": {
        "id": "yPt2LmFFLFUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 2\n",
        "#attaching google sheets for file import\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "DzXavWFHLHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive for file export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hWMd3SofLOMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 3\n",
        "#import file using file name ti pandas df\n",
        "import pandas as pd\n",
        "worksheet = gc.open(inputFileName).get_worksheet(sheetIndex)\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "headers = rows[0]\n",
        "rows = rows[1:]\n",
        "sheetDF = pd.DataFrame.from_records(rows, columns=headers)"
      ],
      "metadata": {
        "id": "kY3fiz33LU9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CheckoutMap = {\n",
        "    \"openRzpCheckout\" : \"Magic\",\n",
        "    \"gokwik-checkout\": \"Gokwik\",\n",
        "    \"flo-checkout\": \"shopflo\",\n",
        "    \"sr-headless-checkout\": \"Fastrr/Shiprocket\",\n",
        "    \"appnova\": \"Appnova\", #need website to verify\n",
        "    \"nimbbl\": \"Nimbbl\", #need website to verify\n",
        "}\n",
        "\n",
        "PlatformMap = {\n",
        "    \"cdn.shopify.com\": \"Shopify\",\n",
        "    \"woocommerce\": \"WooCommerce\",\n",
        "    \"squarespace\": \"SquareSpace\",\n",
        "    \"cdn11.bigcommerce.com\": \"BigCommerce\",\n",
        "    \"Wix.com Website Builder\": \"Wix\",\n",
        "    \"x-cart\": \"X-cart\",\n",
        "    \"bigcartel\": \"Big Cartel\",\n",
        "    \"www.weebly.com\": \"Weebly\",\n",
        "    \"magento\": \"Magento\",\n",
        "    \"prestashop\": \"PrestaShop\",\n",
        "    \"dukaan\": \"Dukaan\",\n",
        "    \"zyrosite\": \"Zyro\"\n",
        "}"
      ],
      "metadata": {
        "id": "v5LjKj-VLVYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining lambda function to check website response\n",
        "import requests\n",
        "\n",
        "def crawl_website(row):\n",
        "    checkout = \"Not found\"\n",
        "    platform = \"Not found\"\n",
        "    try:\n",
        "        # Send an HTTP GET request to the URL\n",
        "        print(row[columnIndex])\n",
        "        response = requests.get(row[columnIndex])\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Get the HTML content of the webpage\n",
        "            html = response.text\n",
        "            # Search for the keywords in the HTML\n",
        "            for keyword, output in CheckoutMap.items():\n",
        "                if keyword in html:\n",
        "                    checkout = output\n",
        "                    break\n",
        "            for keyword, output in PlatformMap.items():\n",
        "                if keyword in html:\n",
        "                    platform = output\n",
        "                    break\n",
        "            row['Checkout'] = checkout\n",
        "            row['Platform'] = platform\n",
        "            return row\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Error occurred while accessing the website:\", e)\n",
        "\n",
        "    row['Checkout'] = checkout\n",
        "    row['Platform'] = platform\n",
        "    return row"
      ],
      "metadata": {
        "id": "cE3t-Hj_LWyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Process sheet using lambda function\n",
        "# subsetDF = sheetDF.head(2)\n",
        "subsetDF = sheetDF\n",
        "subsetDF = subsetDF.apply(crawl_website, axis=1)"
      ],
      "metadata": {
        "id": "-mo9PTQ9Lage"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 4\n",
        "#Upload output\n",
        "print(subsetDF)\n",
        "subsetDF.to_csv('/content/drive/MyDrive/'+outputFileName+'.csv', index=False)"
      ],
      "metadata": {
        "id": "5KduX9mFLd-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}