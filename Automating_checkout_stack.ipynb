{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UtkarshRazor/checkout-stack/blob/main/Automating_checkout_stack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¡ How to Execute the Script?\n",
        "Follow these steps to execute the script and extract website URLs from an Excel column:\n",
        "\n",
        "---\n",
        "1. **Understand the Procedure**:</br>\n",
        " Begin by reviewing the provided procedure to grasp the steps involved in the process.</br>\n",
        "\n",
        "---\n",
        "2. **Provide Details**: Enter the required details for the procedure as mentioned in Step 1. ```Replace the placeholders with the actual values```</br>\n",
        " a. Set the ```inputFileName``` variable to the name of the Excel file containing the data.</br>\n",
        " And make sure that the input file is present in your google drive.</br>\n",
        "  b. Specify the column index with the website URLs using the ```columnIndex``` variable.</br>\n",
        "  c.Specify the sheet index using ```sheetIndex``` vairable.</br>\n",
        "  d. Choose an appropriate name for the output file and set it as the ```outputFileName``` variable.\n",
        "---\n",
        "3. **Run the Script:**</br>\n",
        "Navigate to \"Runtime\" and select \"Run all\" to initiate the script's execution.\n",
        "\n",
        "---\n",
        "4. **Allow Access Popups:**</br>\n",
        "Once the script starts running, you will encounter two popups requesting access permissions.</br>\n",
        "a. Grant access to Google Colab for accessing Google Sheets.</br>\n",
        "b. Grant access to Google Colab for accessing Google Drive. </br>\n",
        "---\n",
        "5. **Wait for Output:**</br>\n",
        "Allow the script to process the data and extract the website URLs.\n",
        "Wait for the script to complete its execution.\n"
      ],
      "metadata": {
        "id": "ZRh548bYKx65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“– **Procedure**\n",
        "---\n",
        "Step 1: *Set Up Variables*</br>\n",
        "1. Assign the input file name to the variable ```inputFileName```.</br>\n",
        "2. Determine the sheet index and assign it to vairable ```sheetIndex```.</br>\n",
        "3. Determine the column index containing website URLs and assign it to the variable ```columnIndex```.</br>\n",
        "> For example, if the website URL is in column A, set ```columnIndex``` to 0.</br>\n",
        "> For column B, set ```columnIndex``` to 1, and so on.</br>\n",
        "\n",
        "4. Assign the desired output file name to the variable ```outputFileName```.</br>\n",
        "Make sure no file with same output name is present in your google drive.\n",
        "\n",
        "---\n",
        "Step 2: *Acess Management*</br>\n",
        "Allow google colab to access drive and google sheets.\n",
        "\n",
        "---\n",
        "Step 3: *Extract details from Website URL*</br>\n",
        "Loop through the selected column's cells and extract the website details.\n",
        "Store the extracted details in a list or an appropriate data structure.\n",
        "\n",
        "---\n",
        "Step 4: *Write to Output File*</br>\n",
        "Create the output file using the outputFileName.\n",
        "Write the extracted website details to the output file.\n",
        "\n",
        "---\n",
        "Step 5: *Completion*</br>\n",
        "Verify the output file in your google drive.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mk0m8wRMK6wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 1\n",
        "inputFileName = 'inputfile'\n",
        "sheetIndex = 0\n",
        "columnIndex = 1\n",
        "outputFileName = 'outputfile'"
      ],
      "metadata": {
        "id": "yPt2LmFFLFUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the number of threads as per your system's capabilities\n",
        "numThreads = 20\n",
        "requestTimeoutSeconds = 10"
      ],
      "metadata": {
        "id": "SwldsnvAN-z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 2\n",
        "#attaching google sheets for file import\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "DzXavWFHLHeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive for file export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWMd3SofLOMA",
        "outputId": "87d79908-3e84-466f-ac74-4c52603a9e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 3\n",
        "#import file using file name ti pandas df\n",
        "import pandas as pd\n",
        "worksheet = gc.open(inputFileName).get_worksheet(sheetIndex)\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "headers = rows[0]\n",
        "rows = rows[1:]\n",
        "sheetDF = pd.DataFrame.from_records(rows, columns=headers)"
      ],
      "metadata": {
        "id": "kY3fiz33LU9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CheckoutMap = {\n",
        "   \"gokwik-checkout\": \"Gokwik\",\n",
        "   \"gokwikSdk.initCheckout\": \"Gokwik\",\n",
        "   \"flo-checkout\": \"shopflo\",\n",
        "   \"openFloCheckout\": \"shopflo\",\n",
        "   \"handleFloCheckoutBtn\": \"shopflo\",\n",
        "   \"sr-headless-checkout\": \"Fastrr/Shiprocket\",\n",
        "   \"appnova\": \"Appnova\", #need website to verify\n",
        "   \"nimbbl\": \"Nimbbl\", #need website to verify\n",
        "   \"zecpe-btn\": \"Zecpe\",\n",
        "   \"openRzpCheckout\" : \"Magic\",\n",
        "   \"razorpayMagicBtnConfig\": \"Magic\",\n",
        "   \"magic-checkout.js\": \"Magic\",\n",
        "   \"magic-rzp\": \"Magic (old)\",\n",
        "   \"RZP_1CC_CSS_SCRIPT\": \"Magic (old)\",\n",
        "   \"1cc_razorpay_checkout\": \"Magic (old)\",\n",
        "}\n",
        "\n",
        "PlatformMap = {\n",
        "    \"cdn.shopify.com\": \"Shopify\",\n",
        "    \"woocommerce\": \"WooCommerce\",\n",
        "    \"squarespace\": \"SquareSpace\",\n",
        "    \"cdn11.bigcommerce.com\": \"BigCommerce\",\n",
        "    \"Wix.com Website Builder\": \"Wix\",\n",
        "    \"x-cart\": \"X-cart\",\n",
        "    \"bigcartel\": \"Big Cartel\",\n",
        "    \"www.weebly.com\": \"Weebly\",\n",
        "    \"magento\": \"Magento\",\n",
        "    \"prestashop\": \"PrestaShop\",\n",
        "    \"dukaan\": \"Dukaan\",\n",
        "    \"zyrosite\": \"Zyro\"\n",
        "}"
      ],
      "metadata": {
        "id": "v5LjKj-VLVYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining lambda function to check website response\n",
        "import requests\n",
        "\n",
        "def crawl_website(url):\n",
        "    checkout = \"Not found\"\n",
        "    platform = \"Not found\"\n",
        "    try:\n",
        "        # Send an HTTP GET request to the URL\n",
        "        print(url)\n",
        "        response = requests.get(url, timeout=requestTimeoutSeconds)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Get the HTML content of the webpage\n",
        "            html = response.text\n",
        "            # Search for the keywords in the HTML\n",
        "            for keyword, output in CheckoutMap.items():\n",
        "                if keyword in html:\n",
        "                    checkout = output\n",
        "                    break\n",
        "            for keyword, output in PlatformMap.items():\n",
        "                if keyword in html:\n",
        "                    platform = output\n",
        "                    break\n",
        "            # row['Checkout'] = checkout\n",
        "            # row['Platform'] = platform\n",
        "            return url + \"|\" + checkout + \"|\" + platform\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"Error occurred while accessing the website:\", e)\n",
        "\n",
        "    # row['Checkout'] = checkout\n",
        "    # row['Platform'] = platform\n",
        "    return url + \"|\" + checkout + \"|\" + platform"
      ],
      "metadata": {
        "id": "cE3t-Hj_LWyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Process sheet using lambda function\n",
        "# subsetDF = sheetDF.head(200)\n",
        "subsetDF = sheetDF\n",
        "# subsetDF = subsetDF.apply(crawl_website, axis=1)"
      ],
      "metadata": {
        "id": "-mo9PTQ9Lage"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Using ThreadPoolExecutor for parallel processing\n",
        "with ThreadPoolExecutor(max_workers=numThreads) as executor:\n",
        "    # Use a list comprehension to collect results from the executor\n",
        "    checkout_platform = list(executor.map(crawl_website, subsetDF.iloc[:, columnIndex]))\n",
        "\n",
        "print('loop_completed')\n",
        "\n",
        "# Add a new column 'Checkout,Platform' to the DataFrame\n",
        "subsetDF['url|Checkout|Platform'] = checkout_platform"
      ],
      "metadata": {
        "id": "rIM_xfpEjhcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title â–¶ STEP 4\n",
        "#Upload output\n",
        "subsetDF[['url','Checkout', 'Platform']] = subsetDF['url|Checkout|Platform'].str.split('|', expand=True)\n",
        "\n",
        "# Drop the original 'Checkout,Platform' column\n",
        "subsetDF.drop('url|Checkout|Platform', axis=1, inplace=True)\n",
        "# print(subsetDF)\n",
        "subsetDF.to_csv('/content/drive/MyDrive/'+outputFileName+'.csv', index=False)"
      ],
      "metadata": {
        "id": "5KduX9mFLd-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}